{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-Based\n",
    "data = pd.read_csv('Test_data.csv')\n",
    "input_data = pd.DataFrame({\n",
    "    'user_id': [190, 190,190,190],\n",
    "    'post_id': [3456,3559,2121,3594]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-Based\n",
    "data = pd.read_csv('Test_data.csv')\n",
    "input_data = pd.DataFrame({\n",
    "    'user_id': [190, 190,190,190],\n",
    "    'post_id': [3602,3600,3570,1715]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaboration Filtering Recommandation\n",
    "data = pd.read_csv('Test_data.csv')\n",
    "input_data = pd.DataFrame({\n",
    "    'user_id': [190, 190,190,190],\n",
    "    'post_id': [1690,3588,1489,1855]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def calculate_similarity(input_data, data):\n",
    "    # Combine input_data and data to ensure all users and posts are included\n",
    "    combined_data = pd.concat([input_data, data])\n",
    "    \n",
    "    # Create a user-post interaction matrix\n",
    "    interaction_matrix = combined_data.pivot_table(index='user_id', columns='post_id', aggfunc='size', fill_value=0)\n",
    "    \n",
    "    similar_users = {}\n",
    "\n",
    "    for input_user_id in input_data['user_id'].unique():\n",
    "        input_user_vector = interaction_matrix.loc[input_user_id]\n",
    "\n",
    "        similar_users[input_user_id] = []\n",
    "        \n",
    "        for user_id in interaction_matrix.index:\n",
    "            if user_id != input_user_id:\n",
    "                user_vector = interaction_matrix.loc[user_id]\n",
    "                \n",
    "                # Calculate Pearson Correlation Coefficient\n",
    "                if len(input_user_vector) > 1 and len(user_vector) > 1:\n",
    "                    correlation, _ = pearsonr(input_user_vector, user_vector)\n",
    "                    if not pd.isna(correlation):  # Ensure the correlation is not NaN\n",
    "                        similar_users[input_user_id].append((user_id, correlation))\n",
    "    \n",
    "    return similar_users\n",
    "\n",
    "\n",
    "def find_top_similar_user(similar_users, top_n):\n",
    "    top_similar_users = {}\n",
    "\n",
    "    for input_user_id, user_similarities in similar_users.items():\n",
    "        user_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_similar_users[input_user_id] = user_similarities[:top_n]\n",
    "\n",
    "    return top_similar_users\n",
    "\n",
    "def recommend_posts(input_data, similar_users, data, top_n=1, min_recommendations=5):\n",
    "    recommendations = {}\n",
    "    \n",
    "    # Counting the frequency of each post in the dataset\n",
    "    post_frequency = Counter(data['post_id'])\n",
    "\n",
    "    for input_user_id, similar_user_list in similar_users.items():\n",
    "        recommendations[input_user_id] = []\n",
    "        \n",
    "        # Posts already seen by the input user\n",
    "        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n",
    "        \n",
    "        # Extend the similar user list if necessary\n",
    "        additional_similar_users = []\n",
    "        if len(similar_user_list) < top_n:\n",
    "            additional_similar_users = similar_users[input_user_id][top_n:top_n*2]\n",
    "\n",
    "        combined_similar_users = similar_user_list + additional_similar_users\n",
    "        \n",
    "        for user_id, similarity_score in combined_similar_users:\n",
    "            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n",
    "            recommended_posts = user_posts - input_user_posts\n",
    "            recommendations[input_user_id].extend(recommended_posts)\n",
    "            \n",
    "            if len(recommendations[input_user_id]) >= min_recommendations:\n",
    "                break\n",
    "        \n",
    "        # If there are still not enough recommendations, add the most frequent posts\n",
    "        if len(recommendations[input_user_id]) < min_recommendations:\n",
    "            frequent_posts = [post for post, _ in post_frequency.most_common() if post not in input_user_posts]\n",
    "            recommendations[input_user_id].extend(frequent_posts[:min_recommendations - len(recommendations[input_user_id])])\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# input_data, similar_users, and data should be defined as per your specific dataset and context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Top similar users-----------------------\n",
      "\n",
      "user_id 190 has top similar to:\n",
      "  user_id 101 with similarity score: 0.7071067811865476,\n",
      "\n",
      "  user_id 102 with similarity score: 0.125,\n",
      "\n",
      "------------------Matching similar personalize-----------------------\n",
      "Input user_id 190 has post_ids: {3456, 2121, 3594, 3559}\n",
      "Matching user_id 101 has post_ids: {3456, 3559, 2121, 3594, 3602, 3540, 1690}\n",
      "\n",
      "\n",
      "Input user_id 190 has post_ids: {3456, 2121, 3594, 3559}\n",
      "Matching user_id 102 has post_ids: {1635, 3602, 3594, 3535}\n",
      "\n",
      "\n",
      "Algorithm User Based ------>  Recommendations personalize:\n",
      "\n",
      "user_id 190 should recommend the following posts:\n",
      "[3602, 3540, 1690, 3602, 1635, 3535]\n",
      "\n",
      "Recommended posts All listed: [3602, 3540, 1690, 3602, 1635, 3535]\n"
     ]
    }
   ],
   "source": [
    "similarities = calculate_similarity(input_data, data)\n",
    "top_similar_users = find_top_similar_user(similarities, top_n=1)\n",
    "recommendations = recommend_posts(input_data, top_similar_users, data)\n",
    "\n",
    "print(\"------------------Top similar users-----------------------\\n\")\n",
    "for input_user_id, similar_user_list in top_similar_users.items():\n",
    "    print(f\"user_id {input_user_id} has top similar to:\")\n",
    "    for user_id, similarity_score in similar_user_list:\n",
    "        print(f\"  user_id {user_id} with similarity score: {similarity_score},\\n\")\n",
    "# Additional print statements\n",
    "print(\"------------------Matching similar personalize-----------------------\")\n",
    "for input_user_id, similar_user_list in top_similar_users.items():\n",
    "    for user_id, similarity_score in similar_user_list:\n",
    "        print(f\"Input user_id {input_user_id} has post_ids: {set(input_data[input_data['user_id'] == input_user_id]['post_id'])}\")\n",
    "        print(f\"Matching user_id {user_id} has post_ids: {set(data[data['user_id'] == user_id]['post_id'])}\")\n",
    "        print(\"\\n\")\n",
    "print(\"Algorithm User Based ------>  Recommendations personalize:\\n\")\n",
    "recommended_posts_listed = []\n",
    "\n",
    "for input_user_id, recommended_posts in recommendations.items():\n",
    "    print(f\"user_id {input_user_id} should recommend the following posts:\")\n",
    "    print(recommended_posts)\n",
    "    recommended_posts_listed.extend(recommended_posts)\n",
    "\n",
    "print(\"\\nRecommended posts All listed:\", recommended_posts_listed)\n",
    "from collections import Counter   \n",
    "# Dictionary to store matching user's post_ids\n",
    "matching_post_ids = {}\n",
    "\n",
    "# Collect matching user's post_ids\n",
    "for input_user_id, similar_user_list in top_similar_users.items():\n",
    "    for user_id, similarity_score in similar_user_list:\n",
    "        input_user_post_ids = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n",
    "        matching_user_post_ids = set(data[data['user_id'] == user_id]['post_id'])\n",
    "        matching_post_ids[input_user_id] = input_user_post_ids.intersection(matching_user_post_ids)\n",
    "\n",
    "# Find the post_id with the most users among matching users\n",
    "most_common_post_id = Counter([post_id for post_ids in matching_post_ids.values() for post_id in post_ids]).most_common(1)[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

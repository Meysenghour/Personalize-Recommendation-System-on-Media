{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4e1Jr4kv1bJ"},"outputs":[],"source":["!pip install scikit-surprise"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cqHxWbW09rPO"},"source":["# Algorithm User-Items Based"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1713927949314,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"SJc0cMFvk9qu"},"outputs":[],"source":["import pandas as pd\n","\n","# Updated dataset\n","# data = pd.DataFrame({\n","#     'user_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 3,3, 4, 4, 4],\n","#     'post_id': [2, 3, 4, 2, 5, 3, 2, 4, 5, 6,7, 2, 4, 9]\n","# })\n","# # Input data\n","# input_data = pd.DataFrame({\n","#     'user_id': [5, 5, 5,7,7,7],\n","#     'post_id': [2, 4, 5,4,9,10]\n","# })\n","data = pd.read_csv('data.csv')\n","input_data = pd.read_csv('input_data.csv')\n","\n","# data = pd.read_csv('blog_viewerpreference_202405080943.csv')\n","# input_data = pd.DataFrame({\n","#     'user_id': [190, 190,185],\n","#     'post_id': [6,56,8]\n","# })"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["data = pd.read_csv('Test_data.csv')\n","input_data = pd.DataFrame({\n","    'user_id': [190, 190,190],\n","    'post_id': [3602,1240,8]\n","})"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713927950955,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"FRmWO2Yik9ne"},"outputs":[],"source":["import pandas as pd\n","from collections import Counter\n","import pandas as pd\n","from scipy.stats import pearsonr\n","\n","\n","def calculate_similarity(input_data, data):\n","    # Combine input_data and data to ensure all users and posts are included\n","    combined_data = pd.concat([input_data, data])\n","    \n","    # Create a user-post interaction matrix\n","    interaction_matrix = combined_data.pivot_table(index='user_id', columns='post_id', aggfunc='size', fill_value=0)\n","    \n","    similar_users = {}\n","\n","    for input_user_id in input_data['user_id'].unique():\n","        input_user_vector = interaction_matrix.loc[input_user_id]\n","\n","        similar_users[input_user_id] = []\n","        \n","        for user_id in interaction_matrix.index:\n","            if user_id != input_user_id:\n","                user_vector = interaction_matrix.loc[user_id]\n","                \n","                # Calculate Pearson Correlation Coefficient\n","                if len(input_user_vector) > 1 and len(user_vector) > 1:\n","                    correlation, _ = pearsonr(input_user_vector, user_vector)\n","                    if not pd.isna(correlation):  # Ensure the correlation is not NaN\n","                        similar_users[input_user_id].append((user_id, correlation))\n","    \n","    return similar_users\n","\n","def find_top_similar_user(similar_users, top_n=1):\n","    top_similar_users = {}\n","\n","    for input_user_id, user_similarities in similar_users.items():\n","        user_similarities.sort(key=lambda x: x[1], reverse=True)\n","        top_similar_users[input_user_id] = user_similarities[:top_n]\n","\n","    return top_similar_users\n","\n","def recommend_posts(input_data, similar_users, data):\n","    recommendations = {}\n","    \n","    # Counting the frequency of each post in the dataset\n","    post_frequency = Counter(data['post_id'])\n","\n","    for input_user_id, similar_user_list in similar_users.items():\n","        recommendations[input_user_id] = []\n","        \n","        # Posts already seen by the input user\n","        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","        \n","        for user_id, similarity_score in similar_user_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            recommended_posts = user_posts - input_user_posts\n","            recommendations[input_user_id].extend(recommended_posts)\n","        \n","        if not recommendations[input_user_id]:\n","            # If there are no recommendations, recommend the most frequent posts\n","            frequent_posts = [post for post, _ in post_frequency.most_common() if post not in input_user_posts]\n","            recommendations[input_user_id].extend(frequent_posts[:5])\n","    \n","    return recommendations"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------Top similar users-----------------------\n","\n","user_id 190 has top similar to:\n","  user_id 103 with similarity score: 0.6666666666666666,\n","\n","------------------Matching similar personalize-----------------------\n","Input user_id 190 has post_ids: {1240, 8, 3602}\n","Matching user_id 103 has post_ids: {1240, 3602}\n","\n","\n","Algorithm User Based ------>  Recommendations personalize:\n","\n","user_id 190 should recommend the following posts:\n","[3600, 3573, 3601, 3594, 3588]\n","\n","Recommended posts All listed: [3600, 3573, 3601, 3594, 3588]\n"]}],"source":["similarities = calculate_similarity(input_data, data)\n","top_similar_users = find_top_similar_user(similarities, top_n=1)\n","recommendations = recommend_posts(input_data, top_similar_users, data)\n","\n","print(\"------------------Top similar users-----------------------\\n\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    print(f\"user_id {input_user_id} has top similar to:\")\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"  user_id {user_id} with similarity score: {similarity_score},\\n\")\n","# Additional print statements\n","print(\"------------------Matching similar personalize-----------------------\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"Input user_id {input_user_id} has post_ids: {set(input_data[input_data['user_id'] == input_user_id]['post_id'])}\")\n","        print(f\"Matching user_id {user_id} has post_ids: {set(data[data['user_id'] == user_id]['post_id'])}\")\n","        print(\"\\n\")\n","print(\"Algorithm User Based ------>  Recommendations personalize:\\n\")\n","recommended_posts_listed = []\n","\n","for input_user_id, recommended_posts in recommendations.items():\n","    print(f\"user_id {input_user_id} should recommend the following posts:\")\n","    print(recommended_posts)\n","    recommended_posts_listed.extend(recommended_posts)\n","\n","print(\"\\nRecommended posts All listed:\", recommended_posts_listed)\n","from collections import Counter   \n","# Dictionary to store matching user's post_ids\n","matching_post_ids = {}\n","\n","# Collect matching user's post_ids\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        input_user_post_ids = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","        matching_user_post_ids = set(data[data['user_id'] == user_id]['post_id'])\n","        matching_post_ids[input_user_id] = input_user_post_ids.intersection(matching_user_post_ids)\n","\n","# Find the post_id with the most users among matching users\n","most_common_post_id = Counter([post_id for post_ids in matching_post_ids.values() for post_id in post_ids]).most_common(1)[0][0]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The post_id with the most users among matching similar users is 1240.\n"]}],"source":["from collections import Counter\n","\n","# Dictionary to store matching user's post_ids\n","matching_post_ids = {}\n","\n","# Collect matching user's post_ids\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        input_user_post_ids = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","        matching_user_post_ids = set(data[data['user_id'] == user_id]['post_id'])\n","        matching_post_ids[input_user_id] = input_user_post_ids.intersection(matching_user_post_ids)\n","\n","# Find the post_id with the most users among matching users\n","most_common_post_id = Counter([post_id for post_ids in matching_post_ids.values() for post_id in post_ids]).most_common(1)[0][0]\n","\n","print(f\"The post_id with the most users among matching similar users is {most_common_post_id}.\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Counts for each unique post_id:\n","post_id\n","956     22\n","983     20\n","940     20\n","1135    19\n","1029    16\n","        ..\n","995      4\n","2262     4\n","1185     4\n","2761     4\n","1051     3\n","Name: count, Length: 95, dtype: int64\n"]}],"source":["import pandas as pd\n","\n","# Read the dataset\n","data = pd.read_csv('data.csv')\n","\n","# Count occurrences of each unique post_id\n","post_id_counts = data['post_id'].value_counts()\n","print(\"Counts for each unique post_id:\")\n","print(post_id_counts)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The post_id with the most users is 940 with 3 users.\n"]}],"source":["import pandas as pd\n","\n","# Read the dataset\n","data = pd.read_csv('input_data.csv')\n","\n","# Group by post_id and aggregate unique user_ids\n","user_ids_per_post = data.groupby('post_id')['user_id'].unique()\n","\n","# Count the number of users for each post_id\n","num_users_per_post = user_ids_per_post.apply(len)\n","\n","# Find the post_id with the most users\n","post_with_most_users = num_users_per_post.idxmax()\n","num_users_most_post = num_users_per_post.max()\n","\n","print(f\"The post_id with the most users is {post_with_most_users} with {num_users_most_post} users.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 95 post_id(s) that have duplicates.\n"]}],"source":["import pandas as pd\n","\n","# Read the dataset\n","data = pd.read_csv('data.csv')\n","\n","# Count occurrences of each post_id\n","post_id_counts = data['post_id'].value_counts()\n","\n","# Filter post_ids with more than one occurrence\n","duplicate_posts = post_id_counts[post_id_counts > 1]\n","\n","# Count the number of post_ids with duplicates\n","num_duplicate_posts = len(duplicate_posts)\n","\n","print(f\"There are {num_duplicate_posts} post_id(s) that have duplicates.\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The post number 940 has been read by 2 users.\n","The post number 948 has been read by 2 users.\n"]}],"source":["import pandas as pd\n","\n","# Read the dataset\n","data = pd.read_csv('data.csv')\n","\n","# Group by 'post_id' and aggregate unique 'user_id's for each post\n","duplicate_users = data.groupby('post_id')['user_id'].agg(set)\n","\n","# Count the number of unique users for each post\n","duplicate_users_count = duplicate_users.apply(len)\n","\n","# Filter posts with more than one user reading them\n","duplicate_posts = duplicate_users_count[duplicate_users_count > 1]\n","\n","# Display the result\n","for post_id, user_ids in duplicate_users.items():\n","    if post_id in duplicate_posts.index:\n","        print(f\"The post number {post_id} has been read by {duplicate_users_count[post_id]} users.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jm9QgaAS87Ok"},"source":["# Algorithm: Items-Items Based"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":550,"status":"ok","timestamp":1714012949357,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"5y0Fk9pW8tWt"},"outputs":[],"source":["import pandas as pd\n","\n","# Updated dataset\n","data = pd.DataFrame({\n","    'user_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4],\n","    'post_id': [2, 3, 4, 2, 6, 3, 2, 4, 5, 6, 2, 4, 9]\n","})\n","# Input data\n","input_data = pd.DataFrame({\n","    'user_id': [5, 5, 5],\n","    'post_id': [2, 4, 5]\n","})"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1713927432442,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"kLTon1P759IV","outputId":"873e4ace-91b8-4c42-8600-d057ac98257e"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------Top similar users-----------------------\n","\n","user_id 168 has top similar to:\n","  user_id 18 with similarity score: 0.6\n","user_id 169 has top similar to:\n","  user_id 20 with similarity score: 0.4\n","------------------Matching similar personalize-----------------------\n","Input user_id 168 has post_ids: \n","{2523, 2468, 2532}\n","user_id 18 has post_ids: \n","{2562, 2468, 2532, 2540, 2523}\n","\n","\n","Input user_id 169 has post_ids: \n","{1024, 1040}\n","user_id 20 has post_ids: \n","{1024, 1040, 1073, 1051, 1053}\n","\n","\n","Algorithm Item Based ------>  Recommendations personalize:\n","\n","user_id 168 should recommend the following posts:\n","[2562, 2540]\n","user_id 169 should recommend the following posts:\n","[1073, 1051, 1053]\n"]}],"source":["# # Sample input data\n","# input_data = pd.DataFrame({'user_id': [3, 3], 'post_id': [3, 4]})\n","# data = pd.DataFrame({'user_id': [1, 1, 2, 2], 'post_id': [1, 3, 1, 3]})\n","def calculate_similarity(input_data, data):\n","    similar_users = {}\n","    user_posts = data.groupby('user_id')['post_id'].apply(set).to_dict()\n","\n","    for input_user_id in input_data['user_id'].unique():\n","        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","        similar_users[input_user_id] = []\n","\n","        for user_id, posts in user_posts.items():\n","            common_posts = input_user_posts.intersection(posts)\n","            if common_posts:\n","                similarity_score = len(common_posts) / len(input_user_posts.union(posts))\n","                similar_users[input_user_id].append((user_id, similarity_score))\n","\n","    return similar_users\n","\n","def find_top_similar_user(similar_users, top_n=1):\n","    top_similar_users = {}\n","\n","    for input_user_id, user_similarities in similar_users.items():\n","        user_similarities.sort(key=lambda x: x[1], reverse=True)\n","        top_similar_users[input_user_id] = user_similarities[:top_n]\n","\n","    return top_similar_users\n","\n","def recommend_posts(input_data, similar_users, data):\n","    recommendations = {}\n","\n","    for input_user_id, similar_user_list in similar_users.items():\n","        recommendations[input_user_id] = []\n","\n","        for user_id, _ in similar_user_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","            recommended_posts = user_posts - input_user_posts\n","            recommendations[input_user_id].extend(recommended_posts)\n","\n","    return recommendations\n","\n","similarities = calculate_similarity(input_data, data)\n","top_similar_users = find_top_similar_user(similarities, top_n=1)\n","recommendations = recommend_posts(input_data, top_similar_users, data)\n","\n","print(\"------------------Top similar users-----------------------\\n\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    print(f\"user_id {input_user_id} has top similar to:\")\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"  user_id {user_id} with similarity score: {similarity_score}\")\n","print(\"------------------Matching similar personalize-----------------------\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"Input user_id {input_user_id} has post_ids: \\n{set(input_data[input_data['user_id'] == input_user_id]['post_id'])}\")\n","        print(f\"user_id {user_id} has post_ids: \\n{set(data[data['user_id'] == user_id]['post_id'])}\")\n","        print(\"\\n\")\n","print(\"Algorithm Item Based ------>  Recommendations personalize:\\n\")\n","for input_user_id, recommended_posts in recommendations.items():\n","    print(f\"user_id {input_user_id} should recommend the following posts:\")\n","    print(recommended_posts)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Items-based"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No item found for the given user and post ID.\n"]}],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import spacy\n","\n","# Load data from CSV files\n","data = pd.read_csv('data.csv')\n","input_data = pd.read_csv('input_data.csv')\n","\n","# Load English language model for spaCy\n","nlp = spacy.load('en_core_web_sm')\n","\n","def preprocess_text(text):\n","    # Tokenize, lemmatize, and remove stop words\n","    if isinstance(text, str):\n","        doc = nlp(text)\n","        tokens = [token.lemma_ for token in doc if not token.is_stop]\n","        processed_text = ' '.join(tokens)\n","        return processed_text\n","    else:\n","        return \"\"\n","\n","# Apply preprocessing to relevant columns\n","data['Article_processed'] = data['Article'].apply(preprocess_text)\n","data['Author_processed'] = data['Author'].apply(preprocess_text)\n","data['Categories_processed'] = data['Categories'].apply(preprocess_text)\n","\n","def calculate_similarity(data):\n","    # Check if data is not empty\n","    if data.empty:\n","        raise ValueError(\"Input data is empty\")\n","\n","    # Prepare feature vectors\n","    tfidf_vectorizer = TfidfVectorizer()\n","    item_features = tfidf_vectorizer.fit_transform(data['Article_processed'] + ' ' + data['Author_processed'] + ' ' + data['Categories_processed'])\n","\n","    # Compute cosine similarity\n","    item_similarity_matrix = cosine_similarity(item_features, item_features)\n","\n","    return item_similarity_matrix\n","\n","def find_similar_items(target_item_index, item_similarity_matrix, data, top_n=5):\n","    # Check if target item index is valid\n","    if target_item_index >= len(data):\n","        raise ValueError(\"Invalid target item index\")\n","\n","    # Retrieve attributes of target item\n","    target_item_attributes = data.iloc[target_item_index]\n","\n","    # Calculate similarity\n","    similarity_scores = item_similarity_matrix[target_item_index]\n","\n","    # Sort similar items\n","    similar_item_indices = similarity_scores.argsort()[::-1][1:top_n+1]\n","\n","    # Output similar items\n","    similar_items = data.iloc[similar_item_indices]\n","\n","    return similar_items\n","\n","# Calculate item similarity matrix\n","item_similarity_matrix = calculate_similarity(data)\n","\n","# Find index of target item\n","target_item_index = data[(data['user_id'] == input_data['user_id'].values[0]) & (data['post_id'] == input_data['post_id'].values[0])].index\n","if not target_item_index.empty:\n","    target_item_index = target_item_index[0]\n","    # Find similar items\n","    similar_items = find_similar_items(target_item_index, item_similarity_matrix, data)\n","\n","    print(\"Recommended similar items:\")\n","    print(similar_items)\n","else:\n","    print(\"No item found for the given user and post ID.\")\n"]},{"cell_type":"markdown","metadata":{"id":"kPilhM44Tsf8"},"source":["# Personalize recommandations Systems Collaboration Filtering"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","\n","# # Updated dataset\n","# data = pd.DataFrame({\n","#     'user_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4],\n","#     'post_id': [2, 4, 6, 2, 4, 3, 2, 4, 5, 6, 2, 4, 9]\n","# })\n","# # Input data\n","# input_data = pd.DataFrame({\n","#     'user_id': [5, 5, 5, 7, 7, 7],\n","#     'post_id': [2, 4, 5, 4, 9, 10]\n","# })"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top similar users:\n","user_id 168 has top similar to:\n","  user_id 18 with similarity score: 0.6\n","user_id 169 has top similar to:\n","  user_id 20 with similarity score: 0.4\n","------------------Matching similar personalize-----------------------\n","Input user_id 168 has post_ids: \n","{2523, 2468, 2532}\n","user_id 18 has post_ids: \n","{2562, 2468, 2532, 2540, 2523}\n","\n","\n","Input user_id 169 has post_ids: \n","{1024, 1040}\n","user_id 20 has post_ids: \n","{1024, 1040, 1073, 1051, 1053}\n","\n","\n","\n","Recommendations:\n","user_id 168 should recommend the following posts:\n","[2562, 2540]\n","user_id 169 should recommend the following posts:\n","[1073, 1051, 1053]\n"]}],"source":["from collections import defaultdict\n","\n","def calculate_similarity(input_data, data):\n","    similar_users = defaultdict(list)\n","    similar_items = defaultdict(list)\n","    user_posts = data.groupby('user_id')['post_id'].apply(set).to_dict()\n","\n","    for input_user_id in input_data['user_id'].unique():\n","        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","\n","        for user_id, posts in user_posts.items():\n","            common_posts = input_user_posts.intersection(posts)\n","            if common_posts:\n","                similarity_score = len(common_posts) / len(input_user_posts.union(posts))\n","                similar_users[input_user_id].append((user_id, similarity_score))\n","                for item in common_posts:\n","                    similar_items[item].append((user_id, similarity_score))\n","\n","    return similar_users, similar_items\n","\n","def find_top_similar_user(similar_users, top_n=1):\n","    top_similar_users = {}\n","\n","    for input_user_id, user_similarities in similar_users.items():\n","        user_similarities.sort(key=lambda x: x[1], reverse=True)\n","        top_similar_users[input_user_id] = user_similarities[:top_n]\n","\n","    return top_similar_users\n","\n","def recommend_posts(input_data, similar_users, similar_items, data):\n","    recommendations = defaultdict(list)\n","\n","    # Merge similar_users and similar_items into a single loop\n","    for input_user_id, similar_list in similar_users.items():\n","        similar_items_list = similar_items[input_user_id]\n","\n","        recommended_posts = set()  # Set to store unique recommended post_ids\n","\n","        for user_id, _ in similar_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","            recommended_posts.update(user_posts - input_user_posts)\n","\n","        for user_id, _ in similar_items_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","            recommended_posts.update(user_posts - input_user_posts)\n","\n","        recommendations[input_user_id].extend(recommended_posts)\n","\n","    return recommendations\n","\n","\n","\n","\n","similar_users, similar_items = calculate_similarity(input_data, data)\n","top_similar_users = find_top_similar_user(similar_users, top_n=1)\n","recommendations = recommend_posts(input_data, top_similar_users, similar_items, data)\n","\n","print(\"Top similar users:\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    print(f\"user_id {input_user_id} has top similar to:\")\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"  user_id {user_id} with similarity score: {similarity_score}\")\n","print(\"------------------Matching similar personalize-----------------------\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"Input user_id {input_user_id} has post_ids: \\n{set(input_data[input_data['user_id'] == input_user_id]['post_id'])}\")\n","        print(f\"user_id {user_id} has post_ids: \\n{set(data[data['user_id'] == user_id]['post_id'])}\")\n","        print(\"\\n\")\n","print(\"\\nRecommendations:\")\n","for input_user_id, recommended_posts in recommendations.items():\n","    print(f\"user_id {input_user_id} should recommend the following posts:\")\n","    print(recommended_posts)\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{1: [105, 106, 103], 2: [106, 107, 108]}\n"]}],"source":["import pandas as pd\n","from collections import Counter\n","\n","def recommend_posts(input_data, similar_users, data):\n","    recommendations = {}\n","    \n","    # Flattening the data into a list of posts for easy counting\n","    all_posts = list(data['post_id'])\n","    post_frequency = Counter(all_posts)\n","\n","    for input_user_id, similar_user_list in similar_users.items():\n","        recommendations[input_user_id] = []\n","        \n","        # Posts already seen by the input user\n","        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","        \n","        for user_id, similarity_score in similar_user_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            recommended_posts = user_posts - input_user_posts\n","            recommendations[input_user_id].extend(recommended_posts)\n","        \n","        if not recommendations[input_user_id]:\n","            # If there are no recommendations, recommend the most frequent posts\n","            frequent_posts = [post for post, _ in post_frequency.most_common() if post not in input_user_posts]\n","            recommendations[input_user_id].extend(frequent_posts[:5])\n","    \n","    return recommendations\n","\n","# Sample data\n","input_data = pd.DataFrame({\n","    'user_id': [1, 1, 2, 2],\n","    'post_id': [101, 102, 103, 104]\n","})\n","\n","data = pd.DataFrame({\n","    'user_id': [3, 3, 4, 4, 5, 5],\n","    'post_id': [101, 105, 103, 106, 107, 108]\n","})\n","\n","similar_users = {\n","    1: [(3, 0.9), (4, 0.8)],\n","    2: [(4, 0.9), (5, 0.8)]\n","}\n","\n","# Get recommendations\n","recommendations = recommend_posts(input_data, similar_users, data)\n","print(recommendations)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOMHnKcphNe8xWvRLTy4fFD","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}

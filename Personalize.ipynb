{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4e1Jr4kv1bJ"},"outputs":[],"source":["!pip install scikit-surprise"]},{"cell_type":"markdown","metadata":{"id":"cqHxWbW09rPO"},"source":["# Algorithm User-Items Based"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1713927949314,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"SJc0cMFvk9qu"},"outputs":[],"source":["import pandas as pd\n","\n","# Updated dataset\n","# data = pd.DataFrame({\n","#     'user_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 3,3, 4, 4, 4],\n","#     'post_id': [2, 3, 4, 2, 5, 3, 2, 4, 5, 6,7, 2, 4, 9]\n","# })\n","# # Input data\n","# input_data = pd.DataFrame({\n","#     'user_id': [5, 5, 5,7,7,7],\n","#     'post_id': [2, 4, 5,4,9,10]\n","# })\n","data = pd.read_csv('data.csv')\n","input_data = pd.read_csv('input_data.csv')"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713927950955,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"FRmWO2Yik9ne"},"outputs":[],"source":["def calculate_similarity(input_data, data):\n","    similar_users = {}\n","    user_posts = data.groupby('user_id')['post_id'].apply(set).to_dict()\n","\n","    for input_user_id in input_data['user_id'].unique():\n","        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","        similar_users[input_user_id] = []\n","\n","        for user_id, posts in user_posts.items():\n","            common_posts = input_user_posts.intersection(posts)\n","            if common_posts:\n","                similarity_score = len(common_posts) / len(input_user_posts.union(posts))\n","                similar_users[input_user_id].append((user_id, similarity_score))\n","\n","    return similar_users\n","\n","def find_top_similar_user(similar_users, top_n=1):\n","    top_similar_users = {}\n","\n","    for input_user_id, user_similarities in similar_users.items():\n","        user_similarities.sort(key=lambda x: x[1], reverse=True)\n","        top_similar_users[input_user_id] = user_similarities[:top_n]\n","\n","    return top_similar_users\n","\n","def recommend_posts(input_data, similar_users, data):\n","    recommendations = {}\n","\n","    for input_user_id, similar_user_list in similar_users.items():\n","        recommendations[input_user_id] = []\n","\n","        for user_id, similarity_score in similar_user_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","            recommended_posts = user_posts - input_user_posts\n","            recommendations[input_user_id].extend(recommended_posts)\n","\n","    return recommendations\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------Top similar users-----------------------\n","\n","user_id 168 has top similar to:\n","  user_id 18 with similarity score: 0.6,\n","\n","user_id 169 has top similar to:\n","  user_id 20 with similarity score: 0.4,\n","\n","------------------Matching similar personalize-----------------------\n","Input user_id 168 has post_ids: {2523, 2468, 2532}\n","Matching user_id 18 has post_ids: {2562, 2468, 2532, 2540, 2523}\n","\n","\n","Input user_id 169 has post_ids: {1024, 1040}\n","Matching user_id 20 has post_ids: {1024, 1040, 1073, 1051, 1053}\n","\n","\n","Algorithm User Based ------>  Recommendations personalize:\n","\n","user_id 168 should recommend the following posts:\n","[2562, 2540]\n","user_id 169 should recommend the following posts:\n","[1073, 1051, 1053]\n","\n","Recommended posts All listed: [2562, 2540, 1073, 1051, 1053]\n"]}],"source":["similarities = calculate_similarity(input_data, data)\n","top_similar_users = find_top_similar_user(similarities, top_n=1)\n","recommendations = recommend_posts(input_data, top_similar_users, data)\n","\n","print(\"------------------Top similar users-----------------------\\n\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    print(f\"user_id {input_user_id} has top similar to:\")\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"  user_id {user_id} with similarity score: {similarity_score},\\n\")\n","# Additional print statements\n","print(\"------------------Matching similar personalize-----------------------\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"Input user_id {input_user_id} has post_ids: {set(input_data[input_data['user_id'] == input_user_id]['post_id'])}\")\n","        print(f\"Matching user_id {user_id} has post_ids: {set(data[data['user_id'] == user_id]['post_id'])}\")\n","        print(\"\\n\")\n","print(\"Algorithm User Based ------>  Recommendations personalize:\\n\")\n","recommended_posts_listed = []\n","\n","for input_user_id, recommended_posts in recommendations.items():\n","    print(f\"user_id {input_user_id} should recommend the following posts:\")\n","    print(recommended_posts)\n","    recommended_posts_listed.extend(recommended_posts)\n","\n","print(\"\\nRecommended posts All listed:\", recommended_posts_listed)\n","    \n","\n","\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>post_id</th>\n","      <th>Article</th>\n","      <th>Author</th>\n","      <th>Categories</th>\n","      <th>Views</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>38</th>\n","      <td>18</td>\n","      <td>2540</td>\n","      <td>AI Revolutionizing Cambodia’s Banking and Fina...</td>\n","      <td>Molika Meas</td>\n","      <td>438</td>\n","      <td>Finance &amp; Banking</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>18</td>\n","      <td>2562</td>\n","      <td>MoU to Promote Climate Resilience</td>\n","      <td>Sreypich Mao</td>\n","      <td>41</td>\n","      <td>Finance &amp; Banking</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>20</td>\n","      <td>1051</td>\n","      <td>Telcotech Signs Deal with Kampus to Expand Dat...</td>\n","      <td>staff writers Kiripost</td>\n","      <td>367</td>\n","      <td>Tech</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>20</td>\n","      <td>1053</td>\n","      <td>National Domain Name Rolled Out</td>\n","      <td>Mengheng Seng</td>\n","      <td>110</td>\n","      <td>Tech</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>20</td>\n","      <td>1073</td>\n","      <td>Cambodian Academics Debate Chatbot Pros and Cons</td>\n","      <td>Hongseng Rov</td>\n","      <td>529</td>\n","      <td>Tech</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    user_id  post_id                                            Article  \\\n","38       18     2540  AI Revolutionizing Cambodia’s Banking and Fina...   \n","39       18     2562                  MoU to Promote Climate Resilience   \n","47       20     1051  Telcotech Signs Deal with Kampus to Expand Dat...   \n","48       20     1053                    National Domain Name Rolled Out   \n","49       20     1073   Cambodian Academics Debate Chatbot Pros and Cons   \n","\n","                    Author  Categories              Views  \n","38             Molika Meas         438  Finance & Banking  \n","39            Sreypich Mao          41  Finance & Banking  \n","47  staff writers Kiripost         367               Tech  \n","48           Mengheng Seng         110               Tech  \n","49            Hongseng Rov         529               Tech  "]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","# Filter the data DataFrame to include only recommended posts\n","recommended_data = data[data['post_id'].isin(recommended_posts_listed)]\n","\n","# Print the filtered DataFrame\n","recommended_data\n"]},{"cell_type":"markdown","metadata":{"id":"jm9QgaAS87Ok"},"source":["# Algorithm: Items-Items Based"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":550,"status":"ok","timestamp":1714012949357,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"5y0Fk9pW8tWt"},"outputs":[],"source":["import pandas as pd\n","\n","# Updated dataset\n","data = pd.DataFrame({\n","    'user_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4],\n","    'post_id': [2, 3, 4, 2, 6, 3, 2, 4, 5, 6, 2, 4, 9]\n","})\n","# Input data\n","input_data = pd.DataFrame({\n","    'user_id': [5, 5, 5],\n","    'post_id': [2, 4, 5]\n","})"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1713927432442,"user":{"displayName":"Mey Senghour","userId":"17768659951968475695"},"user_tz":-420},"id":"kLTon1P759IV","outputId":"873e4ace-91b8-4c42-8600-d057ac98257e"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------Top similar users-----------------------\n","\n","user_id 168 has top similar to:\n","  user_id 18 with similarity score: 0.6\n","user_id 169 has top similar to:\n","  user_id 20 with similarity score: 0.4\n","------------------Matching similar personalize-----------------------\n","Input user_id 168 has post_ids: \n","{2523, 2468, 2532}\n","user_id 18 has post_ids: \n","{2562, 2468, 2532, 2540, 2523}\n","\n","\n","Input user_id 169 has post_ids: \n","{1024, 1040}\n","user_id 20 has post_ids: \n","{1024, 1040, 1073, 1051, 1053}\n","\n","\n","Algorithm Item Based ------>  Recommendations personalize:\n","\n","user_id 168 should recommend the following posts:\n","[2562, 2540]\n","user_id 169 should recommend the following posts:\n","[1073, 1051, 1053]\n"]}],"source":["# # Sample input data\n","# input_data = pd.DataFrame({'user_id': [3, 3], 'post_id': [3, 4]})\n","# data = pd.DataFrame({'user_id': [1, 1, 2, 2], 'post_id': [1, 3, 1, 3]})\n","def calculate_similarity(input_data, data):\n","    similar_users = {}\n","    user_posts = data.groupby('user_id')['post_id'].apply(set).to_dict()\n","\n","    for input_user_id in input_data['user_id'].unique():\n","        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","        similar_users[input_user_id] = []\n","\n","        for user_id, posts in user_posts.items():\n","            common_posts = input_user_posts.intersection(posts)\n","            if common_posts:\n","                similarity_score = len(common_posts) / len(input_user_posts.union(posts))\n","                similar_users[input_user_id].append((user_id, similarity_score))\n","\n","    return similar_users\n","\n","def find_top_similar_user(similar_users, top_n=1):\n","    top_similar_users = {}\n","\n","    for input_user_id, user_similarities in similar_users.items():\n","        user_similarities.sort(key=lambda x: x[1], reverse=True)\n","        top_similar_users[input_user_id] = user_similarities[:top_n]\n","\n","    return top_similar_users\n","\n","def recommend_posts(input_data, similar_users, data):\n","    recommendations = {}\n","\n","    for input_user_id, similar_user_list in similar_users.items():\n","        recommendations[input_user_id] = []\n","\n","        for user_id, _ in similar_user_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","            recommended_posts = user_posts - input_user_posts\n","            recommendations[input_user_id].extend(recommended_posts)\n","\n","    return recommendations\n","\n","similarities = calculate_similarity(input_data, data)\n","top_similar_users = find_top_similar_user(similarities, top_n=1)\n","recommendations = recommend_posts(input_data, top_similar_users, data)\n","\n","print(\"------------------Top similar users-----------------------\\n\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    print(f\"user_id {input_user_id} has top similar to:\")\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"  user_id {user_id} with similarity score: {similarity_score}\")\n","print(\"------------------Matching similar personalize-----------------------\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"Input user_id {input_user_id} has post_ids: \\n{set(input_data[input_data['user_id'] == input_user_id]['post_id'])}\")\n","        print(f\"user_id {user_id} has post_ids: \\n{set(data[data['user_id'] == user_id]['post_id'])}\")\n","        print(\"\\n\")\n","print(\"Algorithm Item Based ------>  Recommendations personalize:\\n\")\n","for input_user_id, recommended_posts in recommendations.items():\n","    print(f\"user_id {input_user_id} should recommend the following posts:\")\n","    print(recommended_posts)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Items-based"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No item found for the given user and post ID.\n"]}],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import spacy\n","\n","# Load data from CSV files\n","data = pd.read_csv('data.csv')\n","input_data = pd.read_csv('input_data.csv')\n","\n","# Load English language model for spaCy\n","nlp = spacy.load('en_core_web_sm')\n","\n","def preprocess_text(text):\n","    # Tokenize, lemmatize, and remove stop words\n","    if isinstance(text, str):\n","        doc = nlp(text)\n","        tokens = [token.lemma_ for token in doc if not token.is_stop]\n","        processed_text = ' '.join(tokens)\n","        return processed_text\n","    else:\n","        return \"\"\n","\n","# Apply preprocessing to relevant columns\n","data['Article_processed'] = data['Article'].apply(preprocess_text)\n","data['Author_processed'] = data['Author'].apply(preprocess_text)\n","data['Categories_processed'] = data['Categories'].apply(preprocess_text)\n","\n","def calculate_similarity(data):\n","    # Check if data is not empty\n","    if data.empty:\n","        raise ValueError(\"Input data is empty\")\n","\n","    # Prepare feature vectors\n","    tfidf_vectorizer = TfidfVectorizer()\n","    item_features = tfidf_vectorizer.fit_transform(data['Article_processed'] + ' ' + data['Author_processed'] + ' ' + data['Categories_processed'])\n","\n","    # Compute cosine similarity\n","    item_similarity_matrix = cosine_similarity(item_features, item_features)\n","\n","    return item_similarity_matrix\n","\n","def find_similar_items(target_item_index, item_similarity_matrix, data, top_n=5):\n","    # Check if target item index is valid\n","    if target_item_index >= len(data):\n","        raise ValueError(\"Invalid target item index\")\n","\n","    # Retrieve attributes of target item\n","    target_item_attributes = data.iloc[target_item_index]\n","\n","    # Calculate similarity\n","    similarity_scores = item_similarity_matrix[target_item_index]\n","\n","    # Sort similar items\n","    similar_item_indices = similarity_scores.argsort()[::-1][1:top_n+1]\n","\n","    # Output similar items\n","    similar_items = data.iloc[similar_item_indices]\n","\n","    return similar_items\n","\n","# Calculate item similarity matrix\n","item_similarity_matrix = calculate_similarity(data)\n","\n","# Find index of target item\n","target_item_index = data[(data['user_id'] == input_data['user_id'].values[0]) & (data['post_id'] == input_data['post_id'].values[0])].index\n","if not target_item_index.empty:\n","    target_item_index = target_item_index[0]\n","    # Find similar items\n","    similar_items = find_similar_items(target_item_index, item_similarity_matrix, data)\n","\n","    print(\"Recommended similar items:\")\n","    print(similar_items)\n","else:\n","    print(\"No item found for the given user and post ID.\")\n"]},{"cell_type":"markdown","metadata":{"id":"kPilhM44Tsf8"},"source":["# Personalize recommandations Systems Collaboration Filtering"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","\n","# # Updated dataset\n","# data = pd.DataFrame({\n","#     'user_id': [1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4],\n","#     'post_id': [2, 4, 6, 2, 4, 3, 2, 4, 5, 6, 2, 4, 9]\n","# })\n","# # Input data\n","# input_data = pd.DataFrame({\n","#     'user_id': [5, 5, 5, 7, 7, 7],\n","#     'post_id': [2, 4, 5, 4, 9, 10]\n","# })"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top similar users:\n","user_id 168 has top similar to:\n","  user_id 18 with similarity score: 0.6\n","user_id 169 has top similar to:\n","  user_id 20 with similarity score: 0.4\n","------------------Matching similar personalize-----------------------\n","Input user_id 168 has post_ids: \n","{2523, 2468, 2532}\n","user_id 18 has post_ids: \n","{2562, 2468, 2532, 2540, 2523}\n","\n","\n","Input user_id 169 has post_ids: \n","{1024, 1040}\n","user_id 20 has post_ids: \n","{1024, 1040, 1073, 1051, 1053}\n","\n","\n","\n","Recommendations:\n","user_id 168 should recommend the following posts:\n","[2562, 2540]\n","user_id 169 should recommend the following posts:\n","[1073, 1051, 1053]\n"]}],"source":["from collections import defaultdict\n","\n","def calculate_similarity(input_data, data):\n","    similar_users = defaultdict(list)\n","    similar_items = defaultdict(list)\n","    user_posts = data.groupby('user_id')['post_id'].apply(set).to_dict()\n","\n","    for input_user_id in input_data['user_id'].unique():\n","        input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","\n","        for user_id, posts in user_posts.items():\n","            common_posts = input_user_posts.intersection(posts)\n","            if common_posts:\n","                similarity_score = len(common_posts) / len(input_user_posts.union(posts))\n","                similar_users[input_user_id].append((user_id, similarity_score))\n","                for item in common_posts:\n","                    similar_items[item].append((user_id, similarity_score))\n","\n","    return similar_users, similar_items\n","\n","def find_top_similar_user(similar_users, top_n=1):\n","    top_similar_users = {}\n","\n","    for input_user_id, user_similarities in similar_users.items():\n","        user_similarities.sort(key=lambda x: x[1], reverse=True)\n","        top_similar_users[input_user_id] = user_similarities[:top_n]\n","\n","    return top_similar_users\n","\n","def recommend_posts(input_data, similar_users, similar_items, data):\n","    recommendations = defaultdict(list)\n","\n","    # Merge similar_users and similar_items into a single loop\n","    for input_user_id, similar_list in similar_users.items():\n","        similar_items_list = similar_items[input_user_id]\n","\n","        recommended_posts = set()  # Set to store unique recommended post_ids\n","\n","        for user_id, _ in similar_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","            recommended_posts.update(user_posts - input_user_posts)\n","\n","        for user_id, _ in similar_items_list:\n","            user_posts = set(data[data['user_id'] == user_id]['post_id'])\n","            input_user_posts = set(input_data[input_data['user_id'] == input_user_id]['post_id'])\n","            recommended_posts.update(user_posts - input_user_posts)\n","\n","        recommendations[input_user_id].extend(recommended_posts)\n","\n","    return recommendations\n","\n","\n","\n","\n","similar_users, similar_items = calculate_similarity(input_data, data)\n","top_similar_users = find_top_similar_user(similar_users, top_n=1)\n","recommendations = recommend_posts(input_data, top_similar_users, similar_items, data)\n","\n","print(\"Top similar users:\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    print(f\"user_id {input_user_id} has top similar to:\")\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"  user_id {user_id} with similarity score: {similarity_score}\")\n","print(\"------------------Matching similar personalize-----------------------\")\n","for input_user_id, similar_user_list in top_similar_users.items():\n","    for user_id, similarity_score in similar_user_list:\n","        print(f\"Input user_id {input_user_id} has post_ids: \\n{set(input_data[input_data['user_id'] == input_user_id]['post_id'])}\")\n","        print(f\"user_id {user_id} has post_ids: \\n{set(data[data['user_id'] == user_id]['post_id'])}\")\n","        print(\"\\n\")\n","print(\"\\nRecommendations:\")\n","for input_user_id, recommended_posts in recommendations.items():\n","    print(f\"user_id {input_user_id} should recommend the following posts:\")\n","    print(recommended_posts)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOMHnKcphNe8xWvRLTy4fFD","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
